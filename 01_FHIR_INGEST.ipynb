{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674aa63-bc87-45d7-9ddf-11a89e010cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a772cf-6f39-46c1-a76b-bd304c160869",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Unlock FHIR with RAG on Vertex AI - Part-01 (Data Ingest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc0b21-0a5a-4c32-b372-9624d84a13f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run the Notebook\n",
    "\n",
    "**_NOTE_**: This notebook has been tested in the following environment:\n",
    "\n",
    "* Python version = 3.10.13\n",
    "\n",
    "<table align=\"center\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/adethyaa/unlock-fhir-with-rag-on-vertexai/blob/main/01_FHIR_INGEST.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/adethyaa/unlock-fhir-with-rag-on-vertexai/blob/main/01_FHIR_INGEST.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/adethyaa/unlock-fhir-with-rag-on-vertexai/blob/main/01_FHIR_INGEST.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b88f6-9934-4b82-a34f-71eaaa774205",
   "metadata": {},
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author | **Vikrama Adethyaa** |\n",
    "|LinkedIn Profile | [Profile](https://www.linkedin.com/in/adethyaa/) |\n",
    "|GitHub Profile | [Vikrama Adethyaa](https://github.com/adethyaa) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e0f8b-8c58-42c0-a427-c0fef6de822b",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Overview\n",
    "\n",
    "This notebook demonstrates building a natural language interface to complex [FHIR](https://fhir.org/about.html) datasets using [Google Cloud’s Vertex AI](https://cloud.google.com/vertex-ai?hl=en).  Leveraging Retrieval Augmented Generation (RAG), Enterprise Knowledge Graphs, and Vector Search, this solution empowers healthcare professionals to query FHIR data with natural language. This demo is inspired by [Sam Schifman's work](https://medium.com/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8993564-2aba-4121-bfaf-26707c4567f2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0101e-93aa-45d4-a0f9-472a2d198ff1",
   "metadata": {},
   "source": [
    "### 2.1. Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "\n",
    "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "\n",
    "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e0dab-155e-4d9d-9895-c0588da7784d",
   "metadata": {},
   "source": [
    "### 2.2. Install Packages and Dependencies\n",
    "Please install the following packages to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d7707-82f7-421f-908f-1d398c1e9537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Vertex AI SDK\n",
    "! pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97732f-ad64-40ff-bea3-f0feb709fd3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 Download Matching Engine Helper Scripts\n",
    "\n",
    "- ***Matching Engine*** is now called ***[Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview)***\n",
    "- The cell below downloads helper functions necessary for the Vertex AI Matching Engine. These functions improve notebook readability. You can find the ***[source code on Github](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/language/use-cases/document-qa/utils).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b5a21-7464-4ef7-adc3-782285d2d309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "util_folder = \"utils\"\n",
    "\n",
    "if not os.path.exists(util_folder):\n",
    "    os.makedirs(util_folder)\n",
    "\n",
    "url_prefix = \"https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/language/use-cases/document-qa/utils\"\n",
    "files = [\"__init__.py\", \"matching_engine.py\", \"matching_engine_utils.py\"]\n",
    "\n",
    "for fname in files:\n",
    "    urllib.request.urlretrieve(f\"{url_prefix}/{fname}\", filename=f\"{util_folder}/{fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea4c31-de61-423d-9e19-09d28c15737f",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Restart Kernel***\n",
    "\n",
    "Run the following cell to restart the kernel or use the button to restart the kernel.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Kindly allow the kernel to finish restarting before continuing. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913677bf-4b62-4b66-aec2-ba9e346fa547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc33f0ce-daa7-4704-8648-202c0bd6e0ea",
   "metadata": {},
   "source": [
    "### 2.4. Authenticating your notebook environment\n",
    "\n",
    "- If you are using **Colab** to run this notebook, run the cell below and continue.\n",
    "- If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7c013-4bd0-4c24-a28d-599f5143eca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79683a19-3adf-46ab-8e71-334683196fbb",
   "metadata": {},
   "source": [
    "**Vertex AI Workbench**\n",
    "- Open a Terminal in the Jupyter notebook\n",
    "- Execute the below command and follow the instructions\n",
    "\n",
    "```bash\n",
    "gcloud auth login\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f061980-d6fa-4b08-8aa2-65c000674e62",
   "metadata": {},
   "source": [
    "### 2.5. Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916368fc-fcaf-49ec-aa35-c3491cfa426c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limit FHIR files loaded for demo purposes\n",
    "# Since Data Ingestion into Neo4J and Vector Search Index takes time, We set the parameter below to control the number of files ingested.\n",
    "DEMO_FILES_INGEST_LIMIT = 20 # @param {type:\"integer\"}\n",
    "\n",
    "# GCP Parameters\n",
    "PROJECT_ID = \"propane-crawler-363311\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "\n",
    "# Neo4J Connection Parameters\n",
    "NEO4J_URL=\"bolt://localhost:7687\" # @param {type:\"string\"}\n",
    "NEO4J_USER=\"neo4j\" # @param {type:\"string\"}\n",
    "NEO4J_PASSWORD=\"password\" # @param {type:\"string\"}\n",
    "\n",
    "# Dimension Vertex PaLM Text Embedding\n",
    "ME_DIMENSIONS = 768 # @param {type:\"integer\"} \n",
    "ME_DISTANCE_MEASURE_TYPE = \"DOT_PRODUCT_DISTANCE\" # @param {type:\"string\"} \n",
    "\n",
    "# Update to bigger SHARDS for larger data volumes & performance\n",
    "# Doc - https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index\n",
    "ME_SHARD_SIZE = \"SHARD_SIZE_SMALL\" # @param [\"SHARD_SIZE_SMALL\", \"SHARD_SIZE_MEDIUM\", \"SHARD_SIZE_LARGE\"] \n",
    "\n",
    "# Vertex AI Vector Search (MatchingEngine) Endpoint Parameters\n",
    "# Doc - https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index\n",
    "\n",
    "# The machine types that you can use to deploy your index\n",
    "ME_ENDPOINT_MACHINE_TYPE = \"e2-standard-2\" # @param [\"n1-standard-16\", \"n1-standard-32\", \"e2-standard-2\", \"e2-standard-16\", \"e2-highmem-16\", \"n2d-standard-32\"] \n",
    "\n",
    "ME_ENDPOINT_MIN_REPLICA_COUNT = 2 # @param {type:\"integer\"} \n",
    "ME_ENDPOINT_MAX_REPLICA_COUNT = 10 # @param {type:\"integer\"} \n",
    "\n",
    "# Vertex AI Vector Search (MatchingEngine) Index Parameters\n",
    "ME_INDEX_NAME = 'fhir_me_index'  # @param {type: \"string\"}\n",
    "ME_EMBEDDING_GCS_DIR = f'{PROJECT_ID}-me-bucket' # @param {type:\"string\"} \n",
    "ME_DESCRIPTION = \"Index for FHIR Resources\" # @param {type:\"string\"} \n",
    "\n",
    "ME_ENHANCED_CONTEXT_INDEX_NAME = f'{ME_INDEX_NAME}_enhanced' # @param {type:\"string\"} \n",
    "ME_ENHANCED_EMBEDDING_GCS_DIR = f'{ME_EMBEDDING_GCS_DIR}_enhanced' # @param {type:\"string\"} \n",
    "ME_ENHANCED_DESCRIPTION = f'Enhanced Context {ME_DESCRIPTION}' # @param {type:\"string\"} \n",
    "\n",
    "\n",
    "\n",
    "# Set the LLM to use\n",
    "VERTEX_AI_MODEL_NAME = 'gemini-1.0-pro-001'\n",
    "TEXT_EMBEDDING_MODEL_NAME = \"textembedding-gecko@003\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f253c06-aa6c-40f0-9eec-d17f8db3366c",
   "metadata": {},
   "source": [
    "### 2.6. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f54b383-6811-4494-9e6f-cc57e4b9b879",
   "metadata": {},
   "source": [
    "**Colab only:** Run the below cell to initialize the Vertex AI SDK. For Vertex AI Workbench, you don't need to run this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da298a4d-bdcd-494f-9dab-de0fd9fe7341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1669cb-591e-4cb6-9eb9-70307c428c9a",
   "metadata": {},
   "source": [
    "<br>*Import Python Libraries*\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Restart python kernel if issues while importing langchain  ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3982e5e8-9a8c-4203-9110-76b239afa014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 0.1.16\n"
     ]
    }
   ],
   "source": [
    "# Utils\n",
    "import os\n",
    "import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "# Google Vertex AI\n",
    "# from google.cloud import aiplatform\n",
    "# print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
    "\n",
    "# Neo4j Helper scripts\n",
    "from utils.NEO4J_Graph import Graph\n",
    "from utils.FHIR_to_string import FHIR_to_string\n",
    "from utils.FHIR_to_graph import resource_to_node, resource_to_edges, flat_fhir_to_json_str\n",
    "\n",
    "# Langchain\n",
    "import langchain\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_google_vertexai import VectorSearchVectorStore\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import (\n",
    "    Namespace,\n",
    "    NumericNamespace,\n",
    ")\n",
    "\n",
    "\n",
    "# Import libraries\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "\n",
    "# Import custom Matching Engine packages\n",
    "from utils.matching_engine import MatchingEngine\n",
    "from utils.matching_engine_utils import MatchingEngineUtils\n",
    "\n",
    "# Import Custom LangChain Retriever\n",
    "from utils.FHIRResourcesRetriever import FHIRResourcesRetriever\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3ac83-23fe-4d26-abf5-46b0dce647ad",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Setup RAG Prerequisites\n",
    "\n",
    "In this section we will create:\n",
    "- Neo4J - local deployment for Enterprise Knowledge Graph\n",
    "- VertexAI VectorSearch - Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17c1c2-25ee-4614-8446-3ab330280399",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1. Deploy Neo4J Docker Container\n",
    "\n",
    "We'll use **Docker** to deploy a local Neo4j instance for demo purposes.  For production environments, we highly recommend Neo4j on Google Cloud Marketplace. [Try Neo4j on Google Cloud Marketplace](https://console.cloud.google.com/marketplace/product/endpoints/prod.n4gcp.neo4j.io?pli=1&mpp=4bfb2414ab973c741b6f067bf06d5575&mpid=%24device%3A18e0c346ea25f9-098a968de268b5-1d525637-384000-18e0c346ea25fa).\n",
    "\n",
    "The command below launches a local Neo4j database Docker container named ***testneo4j***. Let's break down what it does:\n",
    "\n",
    "**Port Mapping:**\n",
    "- 7474: Access the Neo4j web interface through your browser (usually http://localhost:7474).\n",
    "- 7687: Enables communication with Neo4j using the Bolt protocol (essential for working with the database).\n",
    "\n",
    "**Data Volumes:** Folders on your machine ($HOME/neo4j/*) store your database, logs, imports, etc., so your data is safe even if the container stops.\n",
    "\n",
    "**Secure Credentials:** Variables `{NEO4J_USER}` and `{NEO4J_PASSWORD}` set your Neo4j username and password for secure access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d7f89c-a285-43c7-9228-6078390f2a19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: NEO4J_USER={NEO4J_USER}\n",
      "env: NEO4J_PASSWORD={NEO4J_PASSWORD}\n"
     ]
    }
   ],
   "source": [
    "%env NEO4J_USER={NEO4J_USER}\n",
    "%env NEO4J_PASSWORD={NEO4J_PASSWORD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74753b6e-1af0-43e7-bc5e-3ed8a32cef19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Conflict. The container name \"/testneo4j\" is already in use by container \"c11076036c54a06a362119887aa38eebcfe7f287f7f436f8b5b241f0d98e0012\". You have to remove (or rename) that container to be able to reuse that name.\n",
      "See 'docker run --help'.\n"
     ]
    }
   ],
   "source": [
    "! docker run --name testneo4j -p7474:7474 -p7687:7687 -d \\\n",
    "    -v $HOME/neo4j/data:/data \\\n",
    "    -v $HOME/neo4j/logs:/logs \\\n",
    "    -v $HOME/neo4j/import:/var/lib/neo4j/import \\\n",
    "    -v $HOME/neo4j/plugins:/plugins \\\n",
    "    --env NEO4J_AUTH=$NEO4J_USER/$NEO4J_PASSWORD \\\n",
    "    --env='NEO4JLABS_PLUGINS=[\"apoc\"]' \\\n",
    "    neo4j:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52722622-ef65-458b-aae9-cc98121af1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE          COMMAND                  CREATED      STATUS        PORTS                                                                                            NAMES\n",
      "c11076036c54   neo4j:latest   \"tini -g -- /startup…\"   8 days ago   Up 41 hours   0.0.0.0:7474->7474/tcp, :::7474->7474/tcp, 7473/tcp, 0.0.0.0:7687->7687/tcp, :::7687->7687/tcp   testneo4j\n"
     ]
    }
   ],
   "source": [
    "# Check if Docker Container is running\n",
    "! docker ps -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e6b9c-6d70-49b6-ae3c-754f89476301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start the Container if it is not running\n",
    "! docker start testneo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbba084-d2d8-466d-93b8-b813d26b4eae",
   "metadata": {},
   "source": [
    "#### 3.1.1. Connect to Neo4J Database\n",
    "\n",
    "This code block creates a Graph object instance, establishing a connection to the Neo4j database.\n",
    "See **utils/NEO4J_Graph.py** for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d31a64f-3ef0-41fe-9c1b-e34d09abd2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph = Graph(NEO4J_URL, NEO4J_USER, NEO4J_PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae410c5-c84d-4fdd-b8ab-ea905fc1fa1a",
   "metadata": {},
   "source": [
    "#### 3.1.2. Neo4j Database Helper Cells\n",
    "\n",
    "The following three cells contain database management functions. For a new or blank database, you can skip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1dc653-1a32-4fbc-9af2-c1b9d27cadaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AllergyIntolerance', 10],\n",
      " ['CarePlan', 60],\n",
      " ['CareTeam', 60],\n",
      " ['Claim', 3486],\n",
      " ['Condition', 656],\n",
      " ['Device', 39],\n",
      " ['DiagnosticReport', 3100],\n",
      " ['DocumentReference', 1859],\n",
      " ['Encounter', 1859],\n",
      " ['ExplanationOfBenefit', 3486],\n",
      " ['ImagingStudy', 8],\n",
      " ['Immunization', 259],\n",
      " ['Medication', 957],\n",
      " ['MedicationAdministration', 957],\n",
      " ['MedicationRequest', 1627],\n",
      " ['Observation', 13501],\n",
      " ['Patient', 20],\n",
      " ['Procedure', 2966],\n",
      " ['SupplyDelivery', 239]]\n"
     ]
    }
   ],
   "source": [
    "# Get type and number of each FHIR resource in the database\n",
    "resource_metrics = graph.resource_metrics()\n",
    "resource_metrics.sort()\n",
    "pprint(resource_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04cf6497-5998-46bf-aa31-565dab333130",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Metrics:\n",
      "    - Node Count = 37884\n",
      "    - Relationship Count = 190926\n"
     ]
    }
   ],
   "source": [
    "# metrics for counting nodes and relationships\n",
    "node_count, relationship_count = graph.database_metrics()\n",
    "print('Database Metrics:')\n",
    "print(f'    - Node Count = {node_count}')\n",
    "print(f'    - Relationship Count = {relationship_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c61ea78-fd92-470e-a404-f9e7f47a7ce2",
   "metadata": {},
   "source": [
    "### 3.2. Create VertexAI VectorSearch Index\n",
    "\n",
    "This involves the following steps:\n",
    "- Create a GCS Bucket for storing text.\n",
    "- Instantiate embedding model - used for creating vectors of Text.\n",
    "- Create a VectorSearch Streaming Index\n",
    "- Create VectorSearch IndexEndpoint & deploy Index\n",
    "- Create LangChain VectorStore on VertexAI VectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf6d60-9eaa-4f7b-a862-fb19de7ed192",
   "metadata": {},
   "source": [
    "#### 3.2.1. Create GCS Bucket \n",
    "\n",
    "The Google Cloud Storage Bucket will be used by Vector Store Index.\n",
    "[Create and manage your index](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd712a6-8a88-47b3-8805-65cb0d81112b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! set -x && gsutil mb -p $PROJECT_ID -l $REGION gs://$ME_EMBEDDING_GCS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e6e20-2b13-46f4-aac8-a6bace021db5",
   "metadata": {},
   "source": [
    "#### 3.2.2. Instantiate embedding model\n",
    "\n",
    "Load the pre-trained models textembedding-gecko@003 (embedding generation)\n",
    "Learn more about Google's Foundation Models and their capabilities in this [documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_model_apis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b138962e-6942-47f7-986b-d4a8502361a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VertexAIEmbeddings(client=<vertexai.language_models.TextEmbeddingModel object at 0x7ff7e9324e80>, project='propane-crawler-363311', location='us-central1', request_parallelism=5, max_retries=6, stop=None, model_name='textembedding-gecko@003', client_preview=None, temperature=None, max_output_tokens=None, top_p=None, top_k=None, credentials=None, n=1, streaming=False, safety_settings=None, api_transport=None, api_endpoint=None, instance={'max_batch_size': 250, 'batch_size': 250, 'min_batch_size': 5, 'min_good_batch_size': 5, 'lock': <unlocked _thread.lock object at 0x7ff7f3762240>, 'batch_size_validated': False, 'task_executor': <concurrent.futures.thread.ThreadPoolExecutor object at 0x7ff7e92370a0>, 'embeddings_task_type_supported': True, 'get_embeddings_with_retry': <function TextEmbeddingModel.get_embeddings at 0x7ff7e91adb40>})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Text Embedding\n",
    "text_embedding_model = VertexAIEmbeddings(\n",
    "    model_name=TEXT_EMBEDDING_MODEL_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    max_retries=6\n",
    ")\n",
    "\n",
    "text_embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbaf897-cdb3-4c6d-a43b-681c04bf597c",
   "metadata": {},
   "source": [
    "#### 3.2.3. Create a VectorSearch Streaming Index\n",
    "\n",
    "In this step, we'll create the Vector Search Index.\n",
    "\n",
    "For more details, refer to the Create and Manage Index: https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index documentation.\n",
    "Vector Store supports two index types:\n",
    "\n",
    "- **Batch Updates:** Ideal for less frequent modifications.\n",
    "- **Streaming Updates:** Allows near-real-time additions and queries (our choice for this example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c370bc-2b4e-41ef-8813-c18b6502bb02",
   "metadata": {},
   "source": [
    "<br>*Let's create a dummy embeddings file required to initialize the Vector Search Index.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b41b6a-7cf9-403f-85d2-8b46fe157df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Temp folder\n",
    "! mkdir -p $HOME/temp\n",
    "\n",
    "# Create Dummy Embdeddng Data\n",
    "dummy_embedding = {\"id\": str(uuid.uuid4()), \"embedding\": list(np.zeros(ME_DIMENSIONS))}\n",
    "\n",
    "# Write Dummy Embedding Data to a JSON file\n",
    "with open('../temp/dummy_embedding.json', 'w') as f:\n",
    "    json.dump(dummy_embedding, f)\n",
    "    \n",
    "# Copy the dummy_embedding.json to Cloud Storage Bucket.\n",
    "! set -x && gsutil cp ../temp/dummy_embedding.json gs://{ME_EMBEDDING_GCS_DIR}/init_index/dummy_embedding.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d3c682-2d08-4cef-817b-f99eaaacd857",
   "metadata": {},
   "source": [
    "<br>*Let us now create a Streaming Index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e706ff3-73e5-43a1-b4b1-dd0c6f50990b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "me_utils = MatchingEngineUtils(PROJECT_ID, REGION, ME_INDEX_NAME)\n",
    "\n",
    "me_index = me_utils.create_index(\n",
    "    embedding_gcs_uri=f'gs://{ME_EMBEDDING_GCS_DIR}/init_index',\n",
    "    dimensions=ME_DIMENSIONS,\n",
    "    index_update_method='streaming',\n",
    "    index_algorithm='tree-ah',\n",
    "    shard_size= ME_SHARD_SIZE,\n",
    "    distance_measure_type=ME_DISTANCE_MEASURE_TYPE,\n",
    "    description=ME_DESCRIPTION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b02c8a-f2d7-47ce-aada-d05e84fe1f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Details:\n",
      "- Index Name = projects/884766917846/locations/us-central1/indexes/7340819014102286336\n",
      "- Update Method = STREAM_UPDATE\n",
      "- Dimensions = 768.0\n",
      "- Shard Size = SHARD_SIZE_SMALL\n",
      "- Distance Measure Type = DOT_PRODUCT_DISTANCE\n",
      "- Algorithm = treeAhConfig\n"
     ]
    }
   ],
   "source": [
    "# Get information about the Index\n",
    "if me_index:\n",
    "    index_metadata = MessageToDict(me_index._pb)\n",
    "    print('Index Details:')\n",
    "    print(f'- Index Name = {index_metadata[\"name\"]}')\n",
    "    print(f'- Update Method = {index_metadata[\"indexUpdateMethod\"]}')\n",
    "    print(f'- Dimensions = {index_metadata[\"metadata\"][\"config\"][\"dimensions\"]}')\n",
    "    print(f'- Shard Size = {index_metadata[\"metadata\"][\"config\"][\"shardSize\"]}')\n",
    "    print(f'- Distance Measure Type = {index_metadata[\"metadata\"][\"config\"][\"distanceMeasureType\"]}')\n",
    "    algorithm = list(index_metadata[\"metadata\"][\"config\"]['algorithmConfig'].keys())[0]\n",
    "    print(f'- Algorithm = {algorithm}')\n",
    "    # print(f'- Index Stats = {index_metadata[\"indexStats\"]}')\n",
    "\n",
    "# index_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d7067-4af7-4bec-97d9-8a3ab8f1afc2",
   "metadata": {},
   "source": [
    "#### 3.2.4. Create VectorSearch IndexEndpoint & deploy Index\n",
    "\n",
    "In this step, we'll deploy the Index to a Vector Search Index Endpoint. This endpoint is essential for sending queries to your index. \n",
    "\n",
    "We'll use a [Public endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public) for this example. \n",
    "\n",
    "To set up a [Private Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-vpc), please refer to the documentation.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Important: Deploying an Index to an Endpoint takes time, typically around 15-25 minutes or more. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9269c5c7-0d5a-4011-96ce-9cdd90c2e19e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/884766917846/locations/us-central1/indexEndpoints/2407125622317907968\"\n",
       "display_name: \"fhir_me_index-endpoint\"\n",
       "deployed_indexes {\n",
       "  id: \"fhir_me_index_20240429164231\"\n",
       "  index: \"projects/884766917846/locations/us-central1/indexes/7340819014102286336\"\n",
       "  display_name: \"fhir_me_index_20240429164231\"\n",
       "  create_time {\n",
       "    seconds: 1714408951\n",
       "    nanos: 798613000\n",
       "  }\n",
       "  index_sync_time {\n",
       "    seconds: 1715026704\n",
       "    nanos: 855600000\n",
       "  }\n",
       "  deployment_group: \"default\"\n",
       "  dedicated_resources {\n",
       "    machine_spec {\n",
       "      machine_type: \"e2-standard-2\"\n",
       "    }\n",
       "    min_replica_count: 2\n",
       "    max_replica_count: 10\n",
       "  }\n",
       "}\n",
       "etag: \"AMEw9yPoLismCaXpN-kridM5u90IBrVKEZPx9YA1J6Uv0S1WBrtsG9MBlyTzCxmqhag=\"\n",
       "create_time {\n",
       "  seconds: 1714408891\n",
       "  nanos: 533732000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1714408892\n",
       "  nanos: 155730000\n",
       "}\n",
       "public_endpoint_domain_name: \"115788813.us-central1-884766917846.vdb.vertexai.goog\"\n",
       "encryption_spec {\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_endpoint = me_utils.deploy_index(\n",
    "    machine_type=ME_ENDPOINT_MACHINE_TYPE,\n",
    "    min_replica_count=ME_ENDPOINT_MIN_REPLICA_COUNT,\n",
    "    max_replica_count=ME_ENDPOINT_MAX_REPLICA_COUNT,\n",
    "    public_endpoint_enabled=True\n",
    ")\n",
    "\n",
    "me_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac68444a-2d3d-427e-91df-3617c7085520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Name: projects/884766917846/locations/us-central1/indexEndpoints/2407125622317907968\n",
      "Endpoint Public Domain Name: 115788813.us-central1-884766917846.vdb.vertexai.goog\n",
      "Deployed indexes on the endpoint:\n",
      "    - Deployed Indexe ID = fhir_me_index_20240429164231\n",
      "      Machine Type = e2-standard-2\n",
      "      Min Replica Count = 2\n",
      "      Max Replica Count = 10\n"
     ]
    }
   ],
   "source": [
    "if me_endpoint:\n",
    "    endpoint_metadata = MessageToDict(me_endpoint._pb)\n",
    "    print(f'Endpoint Name: {endpoint_metadata[\"name\"]}')\n",
    "    print(f'Endpoint Public Domain Name: {endpoint_metadata[\"publicEndpointDomainName\"]}')\n",
    "    print('Deployed indexes on the endpoint:')\n",
    "    \n",
    "    for d in me_endpoint.deployed_indexes:\n",
    "        print(f'    - Deployed Indexe ID = {d.id}')\n",
    "        print(f'      Machine Type = {d.dedicated_resources.machine_spec.machine_type}')\n",
    "        print(f'      Min Replica Count = {d.dedicated_resources.min_replica_count}')\n",
    "        print(f'      Max Replica Count = {d.dedicated_resources.max_replica_count}')\n",
    "        \n",
    "# endpoint_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce235f8d-787b-4a32-8ef3-d0d6696b4293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ME_INDEX_ID:projects/884766917846/locations/us-central1/indexes/7340819014102286336\n",
      "- ME_INDEX_ENDPOINT_ID:projects/884766917846/locations/us-central1/indexEndpoints/2407125622317907968\n"
     ]
    }
   ],
   "source": [
    "# Get Matching Engine Index id and Endpoint id\n",
    "me_utils = MatchingEngineUtils(PROJECT_ID, REGION, ME_INDEX_NAME)\n",
    "ME_INDEX_ID, ME_INDEX_ENDPOINT_ID = me_utils.get_index_and_endpoint()\n",
    "\n",
    "print(f'- ME_INDEX_ID:{ME_INDEX_ID}\\n- ME_INDEX_ENDPOINT_ID:{ME_INDEX_ENDPOINT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef47d7b-ea3f-49d9-b2a0-4c45ab5df130",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.2.5 Create a LangChain VectorStore instance of VertexAI VectorSearch\n",
    "In this section we create `VectorSearchVectorStore` Object and connect it to the Index & Endpoint We just created.\n",
    "We will also write and retrieve test data to test the connection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cf3aac9-3059-4ccb-9705-d079f750d4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_google_vertexai.vectorstores.vectorstores.VectorSearchVectorStore at 0x7ff7e95ff6a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = VectorSearchVectorStore.from_components(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    gcs_bucket_name=f\"gs://{ME_EMBEDDING_GCS_DIR}\".split(\"/\")[2],\n",
    "    index_id=ME_INDEX_ID,\n",
    "    endpoint_id=ME_INDEX_ENDPOINT_ID,\n",
    "    stream_update=True,\n",
    "    embedding=text_embedding_model\n",
    ")\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bd600-4223-4e23-8cf7-342eec6b39ac",
   "metadata": {},
   "source": [
    "#### 3.2.6. Testing VertexAI VectorSearch\n",
    "\n",
    "We use VertexAI VectorSearch to retrieve relevant FHIR data based on the user's query. The search incorporates:\n",
    "- **Semantic Matching**: Finding Resources with similar text embeddings to the query.\n",
    "- **Metadata Filters**: Narrowing down results based on patient_id and resource_type to ensure relevance. (Refer to the Filter vector matches: https://cloud.google.com/vertex-ai/docs/vector-search/filtering documentation.)\n",
    "\n",
    "A RAG based LLM prompt consist of 3 sections:\n",
    "- **Instructions**: Guidance for the LLM on how to generate an accurate and relevant response based on the retrieved context and the user query.\n",
    "- **Context**: We also apply filters based on patient_id and resource_type to ensure the retrieved context is relevant to the specific patient and the type of information sought. This is a key step, as the accuracy of the LLM's response directly depends on the relevance of this retrieved context. \n",
    "- **User Question**: The original query posed by the user.\n",
    "\n",
    "For Demonstration purpose we will:\n",
    "- First query VectorSearch without Filter.\n",
    "- Next query VectorSearch with Filters. Refer to VectoSearch [Filter vector matches](https://cloud.google.com/vertex-ai/docs/vector-search/filtering) documentation for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276b55f8-255f-450c-b4ff-7ba5c4c6c098",
   "metadata": {},
   "source": [
    "<br>*First, let us add sample data to vectorSearch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37b9ea-a31a-415b-a7d4-3cfe3a12ea53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Sample Data to Ingest\n",
    "resource_text_metadatas = [\n",
    "    {\n",
    "    \"fhir_patient_id\":\"pid_111111111\",\n",
    "    \"fhir_resource_id\":\"rid_111111111\",\n",
    "    \"fhir_resource_type\":\"Test_Resource_type\",\n",
    "    \"neo4j_node_id\": \"nid_111111111\"\n",
    "    },\n",
    "    {\n",
    "    \"fhir_patient_id\":\"pid_222222222\",\n",
    "    \"fhir_resource_id\":\"rid_222222222\",\n",
    "    \"fhir_resource_type\":\"Test_Resource_type\",\n",
    "    \"neo4j_node_id\": \"nid_222222222\"\n",
    "    },\n",
    "    {\n",
    "    \"fhir_patient_id\":\"pid_333333333\",\n",
    "    \"fhir_resource_id\":\"rid_333333333\",\n",
    "    \"fhir_resource_type\":\"Test_Resource_type\",\n",
    "    \"neo4j_node_id\": \"nid_333333333\"\n",
    "    }  \n",
    "]\n",
    "\n",
    "resource_texts = ['This is a sample Resource Type', 'This is a sample Patient Type', 'This is a sample Car Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c084756-0468-4e64-a552-2d9b49d10049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write Sample Data to VectorSearch\n",
    "ids = vector_store.add_texts(texts=resource_texts, \n",
    "                             metadatas=resource_text_metadatas, \n",
    "                             is_complete_overwrite=True)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beeff7a-d39b-46e9-a9a7-a4a6b21fe76a",
   "metadata": {},
   "source": [
    "<br>*Query VectorSearch without Filter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dee9c72-da94-43ec-b23f-7550c4781ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='The type of information in this entry is medication request. The status for this medication request is stopped. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is Meperidine Hydrochloride 50 MG Oral Tablet. This medication request was authored on on 05/29/2020 at 14:05:04.', metadata={'fhir_patient_id': ['05c4608d-bd9a-5d04-41d7-a0293da7f5a5'], 'fhir_resource_id': ['e8ad9b97-911c-5606-a8f8-9e5e740ee5a7'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:694']}),\n",
       "  0.8120825290679932),\n",
       " (Document(page_content='The type of information in this entry is medication request. The status for this medication request is stopped. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is lisinopril 10 MG Oral Tablet. This medication request was authored on on 06/08/2020 at 03:03:15. The reason reference display for this medication request is Essential hypertension (disorder).', metadata={'fhir_patient_id': ['076a24c5-c7f3-c743-e882-34b41a8af35b'], 'fhir_resource_id': ['ad3753aa-ab5c-48a7-2e94-9bb709aba2b5'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:7696']}),\n",
       "  0.810465395450592),\n",
       " (Document(page_content='The type of information in this entry is medication request. The status for this medication request is stopped. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is lisinopril 10 MG Oral Tablet. This medication request was authored on on 01/01/2022 at 10:57:23. The reason reference display for this medication request is Essential hypertension (disorder).', metadata={'fhir_patient_id': ['c1d8ab2f-c0b3-ea11-9ac8-a39c8123564a'], 'fhir_resource_id': ['1512d9de-e559-ca0a-b448-7bfaa2c7dcfc'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:21997']}),\n",
       "  0.8104639649391174),\n",
       " (Document(page_content='The type of information in this entry is medication request. The status for this medication request is stopped. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is lisinopril 10 MG Oral Tablet. This medication request was authored on on 01/07/2023 at 10:57:23. The reason reference display for this medication request is Essential hypertension (disorder).', metadata={'fhir_patient_id': ['c1d8ab2f-c0b3-ea11-9ac8-a39c8123564a'], 'fhir_resource_id': ['7dc2a10d-8d41-f057-4724-68221a0685d3'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:22027']}),\n",
       "  0.8102648258209229),\n",
       " (Document(page_content='The type of information in this entry is medication request. The status for this medication request is stopped. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is lisinopril 10 MG Oral Tablet. This medication request was authored on on 01/01/2019 at 19:34:01. The reason reference display for this medication request is Essential hypertension (disorder).', metadata={'fhir_patient_id': ['1d3e046a-bfde-008e-4546-9d9b8184c2bf'], 'fhir_resource_id': ['8cdbae4f-d122-be97-2b9a-4ba5894e1bec'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:20519']}),\n",
       "  0.8101488947868347),\n",
       " (Document(page_content='The type of information in this entry is medication request. The status for this medication request is stopped. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is lisinopril 10 MG Oral Tablet. This medication request was authored on on 04/07/1996 at 07:28:01. The reason reference display for this medication request is Essential hypertension (disorder).', metadata={'fhir_patient_id': ['ded32e6b-fed4-bee1-c697-2e79957caa7a'], 'fhir_resource_id': ['cd9e2710-1f3c-bddf-e443-a98d4df2955a'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:18579']}),\n",
       "  0.8101300597190857),\n",
       " (Document(page_content='The type of information in this entry is medication request. The status for this medication request is active. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is 24 HR metoprolol succinate 100 MG Extended Release Oral Tablet. This medication request was authored on on 11/11/1987 at 06:56:35.', metadata={'fhir_patient_id': ['05c4608d-bd9a-5d04-41d7-a0293da7f5a5'], 'fhir_resource_id': ['2d4a3ae2-5ec7-6bc9-19b2-111775f9bd4d'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:105']}),\n",
       "  0.8100528717041016),\n",
       " (Document(page_content='The type of information in this entry is medication request. The status for this medication request is stopped. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is lisinopril 10 MG Oral Tablet. This medication request was authored on on 01/10/2023 at 11:00:10. The reason reference display for this medication request is Essential hypertension (disorder).', metadata={'fhir_patient_id': ['50164fde-695f-07dc-9e8b-6c7107fe40c8'], 'fhir_resource_id': ['bceb6810-4505-ae14-8b64-b7cc01d99d68'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:26315']}),\n",
       "  0.8098453283309937),\n",
       " (Document(page_content='The type of information in this entry is medication request. The status for this medication request is stopped. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is lisinopril 10 MG Oral Tablet. This medication request was authored on on 07/06/2020 at 03:03:15. The reason reference display for this medication request is Essential hypertension (disorder).', metadata={'fhir_patient_id': ['076a24c5-c7f3-c743-e882-34b41a8af35b'], 'fhir_resource_id': ['ffd10270-8134-16cb-0983-eb167dd926e6'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:7902']}),\n",
       "  0.8097641468048096),\n",
       " (Document(page_content='The type of information in this entry is medication request. The status for this medication request is stopped. The intent for this medication request is order. The category of this medication request is Community. The medication codeable concept for this medication request is lisinopril 10 MG Oral Tablet. This medication request was authored on on 06/03/2021 at 01:09:49. The reason reference display for this medication request is Essential hypertension (disorder).', metadata={'fhir_patient_id': ['e1a90b76-c8fb-724a-5053-7355db36519b'], 'fhir_resource_id': ['64f2b28c-52ad-6c6f-84dc-1be1d6698e56'], 'fhir_resource_type': ['MedicationRequest'], 'neo4j_node_id': ['4:19fee34a-16b7-4325-ac38-466e532042ee:2276']}),\n",
       "  0.8097047805786133)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text = 'this type is a medication request'\n",
    "response = vector_store.similarity_search_with_score(query=query_text, k=10)\n",
    "\n",
    "response \n",
    "\n",
    "# Note: The response will likely contain all 3 data points. \n",
    "# Although they have different lexical forms (Sample Resource, Sample Process), \n",
    "# they share the same semantic meaning related to \"sample,\" which is what our\n",
    "# semantic search is designed to capture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f87b44-0b16-4258-81c3-89f00918af6e",
   "metadata": {},
   "source": [
    "<br>*Query VectorSearch with Filters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f979bdf-37cb-40c6-a00a-a943f9795e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieving Data from VectorSearch with Filter\n",
    "\n",
    "vs_filter = [Namespace(name=\"fhir_patient_id\", allow_tokens=['pid_111111111'])]\n",
    "response = vector_store.similarity_search_with_score(query=query_text, k=10, filter=vs_filter)\n",
    "response\n",
    "\n",
    "# Note: We now expect a single data point in the results, as we've applied a filter to retrieve\n",
    "# only the resource associated with the specific patient ID ('fhir_patient_id=pid_111111111'). \n",
    "# This filter ensures we're focusing on information relevant to this particular patient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03096b-bc95-4740-a28a-f7ea4efec943",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 4. Fetch FHIR Synthetic Data\n",
    "\n",
    "Now that we established the prerequiste Infrastructure, let us fetch the sample data.\n",
    "\n",
    "We will be using sample FHIR data from [Synthea](https://synthea.mitre.org/) for the purpose of this demonstration. \n",
    "We will be using the pre-generated data available [here](https://synthetichealth.github.io/synthea-sample-data/downloads/latest/synthea_sample_data_fhir_latest.zip). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb6154-8bf6-4b94-8960-7dcc55e6d54c",
   "metadata": {},
   "source": [
    "### 4.1. Download synthetic FHIR Data from Synthea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b652574-b870-4d1a-ac40-d31ca2738f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p $HOME/working\n",
    "\n",
    "! curl  \\\n",
    "--url https://synthetichealth.github.io/synthea-sample-data/downloads/latest/synthea_sample_data_fhir_latest.zip \\\n",
    "--output $HOME/working/synthea_sample_data_fhir_latest.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d86884-d640-4c5b-a00a-f3aadf47afd6",
   "metadata": {},
   "source": [
    "<br>*Unzip the synthea_sample_data_fhir_latest.zip*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a02767-6f2e-4b3a-b583-77c3b654468b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! unzip $HOME/working/synthea_sample_data_fhir_latest.zip -d $HOME/working/bundles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc942558-b2af-4a4e-89b8-b5944f2eef66",
   "metadata": {},
   "source": [
    "### 4.2. Taking Inventory of FHIR Files\n",
    "\n",
    "<br>*Let us look at the attributes of the FHIR Data we are going to ingest.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c2e20-ebc2-413b-969e-dde035111f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feth all FHIR Files\n",
    "fhir_folder_path = '../working/bundles'\n",
    "fhir_files_list = glob.glob(f\"{fhir_folder_path}/*.json\")\n",
    "\n",
    "# Limiting files to ingest\n",
    "fhir_files_list.sort()\n",
    "fhir_files_list = fhir_files_list[:DEMO_FILES_INGEST_LIMIT]\n",
    "\n",
    "\n",
    "num_of_files = len(fhir_files_list)\n",
    "print(f'Number of FHIR Files that would be ingested: {num_of_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08d65a-8c89-449b-9033-ee5631595480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_counter = 1\n",
    "total_resources = 0\n",
    "file_resources_meta_list = []\n",
    "resource_types_count = {}\n",
    "\n",
    "for fhir_file in fhir_files_list:\n",
    "    fhir_file_name = os.path.basename(fhir_file)\n",
    "    # print(f'File {file_counter} of {num_of_files}: {fhir_file_name}')\n",
    "    file_counter += 1\n",
    "    \n",
    "    with open(fhir_file) as raw:\n",
    "        bundle = json.load(raw)\n",
    "        resources_entry_list = bundle['entry']\n",
    "            \n",
    "        # Resources Counter\n",
    "        num_of_resources = len(resources_entry_list)\n",
    "        total_resources += num_of_resources\n",
    "        file_resources_meta = {}\n",
    "        file_resources_meta['file_name'] = fhir_file_name\n",
    "        file_resources_meta['resources_count'] = num_of_resources\n",
    "        \n",
    "        file_resources_meta_list.append(file_resources_meta)\n",
    "        \n",
    "        # Count Individual Resource Types\n",
    "        for entry in resources_entry_list:\n",
    "            resource = entry['resource']\n",
    "            resource_type = resource[\"resourceType\"]\n",
    "\n",
    "            if resource_type not in resource_types_count.keys():\n",
    "                # print(f'Creating Dict entry for Resource: {resource_type}')\n",
    "                resource_types_count[resource_type] = 0\n",
    "            \n",
    "            resource_types_count[resource_type] += 1\n",
    "\n",
    "\n",
    "print(f'Resource Types Count:')\n",
    "pprint(resource_types_count)\n",
    "\n",
    "print('\\nFile Resources Meta:')\n",
    "pprint(file_resources_meta_list)\n",
    "\n",
    "print('\\n### Summary ###')\n",
    "print(f'- Number of FHIR Files to process = {num_of_files}')            \n",
    "print(f'- Total Resources:{total_resources}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2eaae4-9ad0-44ee-97c9-a21c93b8814c",
   "metadata": {},
   "source": [
    "## 5. Neo4J Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba3ea1-acf2-4716-834c-bb115a2707f2",
   "metadata": {},
   "source": [
    "### 5.1. Neo4J Data Loading Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98a33e-87b7-486b-ac8f-03c0674a6824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create FHIR Resource nodes in Neo4j\n",
    "def create_resource_node(resource:dict) -> str:\n",
    "    # print(resource_to_node(resource))\n",
    "    node_creation_cypher = resource_to_node(resource)\n",
    "    query_result, runtime = graph.query(node_creation_cypher)\n",
    "    \n",
    "    if len(query_result[0]) != 1:\n",
    "        print(query_result)\n",
    "        raise Exception(\"Resource Node creation query result does not meet defined format.\")\n",
    "       \n",
    "    node_id = query_result[0][0]\n",
    "    return node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896709c4-5a2d-4b0c-8a05-2cb90d1cb617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Date Nodes and Edges between Resource Nodes and Date Nodes\n",
    "def create_date_nodes_edges(resource):\n",
    "    edges = []\n",
    "    dates = set() # set is used here to make sure dates are unique\n",
    "\n",
    "    # generated the cypher for creating the reference & date edges and capture dates\n",
    "    node_edges, node_dates = resource_to_edges(resource)\n",
    "    edges += node_edges\n",
    "    dates.update(node_dates)\n",
    "    \n",
    "    # Create Date Nodes - 'MERGE' Skip if Node exists\n",
    "    for date in dates:\n",
    "        cypher = 'MERGE (n:Date {name:\"' + date + '\", id: \"' + date + '\"})'\n",
    "        graph.query(cypher)\n",
    "    \n",
    "    # Connect Resource Nodes and Date Nodes via Edges \n",
    "    for edge in edges:\n",
    "        try:\n",
    "            graph.query(edge)\n",
    "        except:\n",
    "            print(f'Failed to create edge: {edge}')\n",
    "    \n",
    "    return len(dates), len(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f0949-0851-49bc-bbde-abf566020d37",
   "metadata": {},
   "source": [
    "### 5.2. FHIR to Neo4J Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63d024-d76e-4ff3-be49-2604f55801c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_fhir_neo4j(fhir_files_list):\n",
    "    file_counter = 0\n",
    "    \n",
    "    for fhir_file in fhir_files_list:\n",
    "        \n",
    "        fhir_file_name = os.path.basename(fhir_file)\n",
    "        file_counter += 1\n",
    "        \n",
    "        if file_counter > 1:\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        print(f'File {file_counter} of {num_of_files}: {fhir_file_name}')\n",
    "        \n",
    "        with open(fhir_file) as raw:\n",
    "            bundle = json.load(raw)\n",
    "            resources_entry_list = bundle['entry']\n",
    "            \n",
    "            num_of_resources = len(resources_entry_list)\n",
    "            print(f'    - Number of resources = {num_of_resources}')\n",
    "                \n",
    "            resource_counter = 0\n",
    "            for entry in resources_entry_list:\n",
    "                resource_counter += 1\n",
    "                \n",
    "                resource = entry['resource']\n",
    "                # print(resource)\n",
    "                resource_id = resource[\"id\"]\n",
    "                resource_type = resource[\"resourceType\"]\n",
    "                \n",
    "                # Skip Provenance Resource\n",
    "                if resource_type == 'Provenance':\n",
    "                    continue\n",
    "\n",
    "                    \n",
    "                print(f'    - Processing Resource {resource_counter} of {num_of_resources}: Resource-Type = {resource_type}, Resource-ID = {resource_id}', end=\"\\r\", flush=True)\n",
    "                \n",
    "                #### LOAD DATA INTO NEO4J ####\n",
    "                \n",
    "                # Create Resource Nodes\n",
    "                node_id = create_resource_node(resource)\n",
    "                # print (node_id)\n",
    "                \n",
    "                # Create Date Nodes and Edges to connect Resource Nodes to Date Nodes\n",
    "                date_nodes_count, edges_count = create_date_nodes_edges(resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9514fd83-8890-4c11-a3c1-4095691f5f25",
   "metadata": {},
   "source": [
    "### 5.3 Neo4J Data Retrieval Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef39f8-c280-4049-852f-d9b52b9664ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nodes_in_batches(graph, batch_size=1000):\n",
    "    skip = 0\n",
    "    while True:\n",
    "        query_string = f'MATCH (r:resource) RETURN r SKIP {skip} LIMIT {batch_size}'        \n",
    "        # print(query_string)\n",
    "        results = graph.query(query_string)\n",
    "        nodes = results[0]\n",
    "        \n",
    "        if not nodes:\n",
    "            break  # No more nodes to fetch\n",
    "        \n",
    "        yield nodes  # Process this batch\n",
    "        skip += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0374c-b87e-4200-838b-f45984df9c89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print report on Resource nodes\n",
    "def get_neo4j_resourceNodes_stats():\n",
    "    batch_counter = 0\n",
    "    resource_counter = 0\n",
    "    resources_types_dict = {}\n",
    "\n",
    "    for batch in get_nodes_in_batches(graph):\n",
    "        batch_counter += 1\n",
    "        # print(f'Batch: {batch_counter}, Len of Batch = {len(batch)}')\n",
    "\n",
    "        for node in batch:\n",
    "            resource_counter += 1\n",
    "            resource_type = node[0]['resource_type']\n",
    "\n",
    "            if resource_type not in resources_types_dict.keys():\n",
    "                resources_types_dict[resource_type] = 0\n",
    "\n",
    "            resources_types_dict[resource_type] += 1\n",
    "            # print(node[0])\n",
    "\n",
    "    sorted_dict = dict(sorted(resources_types_dict.items()))\n",
    "    pprint(sorted_dict)\n",
    "    print(f'Total Resource Nodes = {resource_counter}')\n",
    "    \n",
    "get_neo4j_resourceNodes_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30fbc1a-e7f3-4d4b-90d3-e7446d4fc873",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 6. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7a0e7-2962-490e-86e3-0a780a910a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set to True to Ingest Data. This is a safety swithc to prevent accidental triggering of Data Ingestion\n",
    "ingest_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b48ce-0bc1-4781-8cf0-79d806cdc0ef",
   "metadata": {},
   "source": [
    "### 6.1. Trigger Neo4J Data Ingestion\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Important: This process may take several hours to complete depending on the number of files and FHIR resources you are ingesting!⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88f40e-7909-402c-b58d-a408021b6c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ingest_data:\n",
    "    start_time = time.time()\n",
    "    load_fhir_neo4j(fhir_files_list)\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_duration = str(datetime.timedelta(seconds = end_time - start_time))\n",
    "    print(f'\\nData Loading Completed in {total_duration}')\n",
    "else:\n",
    "    print(f'Set ingest_data to True to ingest data. Currently ingest_data={ingest_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ddfb62-e2c3-4f84-b9a6-7256416665fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Report on Ingested Data\n",
    "get_neo4j_resourceNodes_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbe2030-09cd-4165-b319-6404ce8f701b",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### 6.2. VectorSearch Data Ingestion Helper Scripts\n",
    "[Vertex AI Vector Search Docs](https://cloud.google.com/vertex-ai/docs/vector-search/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1edf048-9efe-4165-9ec5-324831352c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Load Resource Text to Vector Search ####\n",
    "\n",
    "def add_resource_text_embedding(resource_data):      \n",
    "    \n",
    "    resource_text_metadata = {\n",
    "        \"fhir_patient_id\": [resource_data['patient_id']],\n",
    "        \"fhir_resource_id\": [resource_data['resource_id']],\n",
    "        \"fhir_resource_type\": [resource_data['resource_type']],\n",
    "        \"neo4j_node_id\": [resource_data['neo4j_id']]\n",
    "    }\n",
    "\n",
    "    # Add Resource Text Embeddings to Vector Search\n",
    "    resource_text = resource_data['resource_text']\n",
    "    if resource_text is not None:\n",
    "        try:\n",
    "            # ids = me.add_texts(texts=[resource_text], metadatas=[resource_text_metadata])\n",
    "            ids = vector_store.add_texts(texts=[resource_text], metadatas=[resource_text_metadata], is_complete_overwrite=True)\n",
    "            return ids\n",
    "        except Exception as err:\n",
    "            print(f\"\\nERROR: Unexpected while adding embeddings {err=}, {type(err)=}\")\n",
    "            print(f'Resource_Text = {resource_text}')\n",
    "            print(f'Resource Metadata = {resource_text_metadata}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec2491-21ad-48ad-b77b-0cb3d4cc3033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_related_resource_node_texts(neo4j_node_id: str) -> str:\n",
    "    contextualize_query = f\"\"\"\n",
    "    MATCH (node :resource)\n",
    "    WHERE elementId(node)='{neo4j_node_id}'\n",
    "    MATCH(node)<-[]->(sc:resource)\n",
    "    with node.text as self, reduce(s=\"\", item in collect(distinct sc.text) | s + \"\\n\\nSecondary Entry:\\n\" + item ) as ctxt limit 1\n",
    "    return \"Primary Entry:\\n\" + self + ctxt as text\"\"\"\n",
    "\n",
    "    resource_text = graph.query(contextualize_query)[0][0][0]\n",
    "    \n",
    "    return resource_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70108bf5-e875-46ff-b16b-66d1cf5efa06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add Text Embeddings of all Resource Text to Vector Search\n",
    "\n",
    "def create_embeddings_of_all_resource_text():\n",
    "    batch_counter = 0\n",
    "    resource_counter = 0\n",
    "    resources_types_dict = {}\n",
    "    \n",
    "    resource_counter = 0\n",
    "    vector_ids_csv_file = 'vector_ids.csv'\n",
    "    with open(vector_ids_csv_file, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['S.NO','FHIR_RESOURCE_ID','VECTORSEARCH_ID', 'PATIENT_ID'])\n",
    "    \n",
    "    # Since we have large number of Resources, we iterate in batches\n",
    "    for batch in get_nodes_in_batches(graph):\n",
    "        batch_counter += 1\n",
    "        # print(f'Batch: {batch_counter}, Len of Batch = {len(batch)}')\n",
    "        \n",
    "        for node in batch:\n",
    "            resource_counter += 1\n",
    "            resource_data = {\n",
    "                'neo4j_id': node[0].element_id,\n",
    "                'resource_id': node[0]['id'],\n",
    "                'resource_type': node[0]['resource_type'],\n",
    "                # 'resource_text': node[0]['text']        \n",
    "            }\n",
    "            \n",
    "            # Get related Patient ID of the Resource\n",
    "            resource_data['patient_id'] = \"\"\n",
    "            if node[0]['resource_type'] == 'Patient':\n",
    "                # print (node[0])\n",
    "                resource_data['patient_id'] = node[0]['id']\n",
    "            elif node[0]['subject_reference']:\n",
    "                resource_data['patient_id'] = node[0]['subject_reference'].split(':')[-1]\n",
    "            elif node[0]['patient_reference']: \n",
    "                resource_data['patient_id'] = node[0]['patient_reference'].split(':')[-1] \n",
    "            else:\n",
    "                print(f\"no patient id for resource_id: {node[0]['resource_id']}, resource_type: {node[0]['resource_type']}\")\n",
    "                # break\n",
    "\n",
    "            resource_data['resource_text'] = node[0]['text']\n",
    "\n",
    "\n",
    "            print(f\"Processing patient_id: {resource_data['patient_id']} node_id: {resource_data['neo4j_id']}, resource_id={resource_data['resource_id']}, resource_type={resource_data['resource_type']}\", end='\\r', flush=True)\n",
    "\n",
    "            # Create Embedding & Add to VectorSearch\n",
    "            ids = add_resource_text_embedding(resource_data)\n",
    "            print(f'Vector Search_ID: {ids}', end='\\r', flush=True)\n",
    "            \n",
    "            with open(vector_ids_csv_file, 'a', newline='') as csv_file:\n",
    "                resource_counter += 1\n",
    "                writer = csv.writer(csv_file)\n",
    "                \n",
    "                if ids is not None:\n",
    "                    writer.writerow([resource_counter, resource_data[\"resource_id\"], ids[0], resource_data['patient_id']])\n",
    "                else:\n",
    "                    writer.writerow([resource_counter, resource_data[\"resource_id\"], '', resource_data['patient_id']])                \n",
    "                \n",
    "            # break\n",
    "            \n",
    "            resource_type = resource_data['resource_type']\n",
    "            if resource_type not in resources_types_dict.keys():\n",
    "                resources_types_dict[resource_type] = 0\n",
    "\n",
    "            resources_types_dict[resource_type] += 1\n",
    "\n",
    "        # break\n",
    "    print(f'\\nProcessed Resources: {resource_counter}')\n",
    "    print('Resources Types Processed:')\n",
    "    print(resources_types_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ec42b-3a6c-4725-a52f-3c492991099c",
   "metadata": {},
   "source": [
    "### 6.3 Trigger VectorSearch Data Ingestion\n",
    "In the Cell below we are creating Embeddings of Resource Text and ingesting it into Vertex AI Vector Search.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Important: This process may take several hours to complete depending on the number of files and FHIR resources you are ingesting! ⚠️</b>\n",
    "</div>\n",
    "\n",
    "To monitor ingest progress, open a new bash terminal and run the below command:\n",
    "```bash\n",
    "tail -f unlock-fhir-with-rag-on-vertexai/vector_ids.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e2cb2-ea5f-4c32-9fa9-c5a484f5b378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ingest_data:\n",
    "    start_time = time.time()\n",
    "    create_embeddings_of_all_resource_text()\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_duration = str(datetime.timedelta(seconds = end_time - start_time))\n",
    "    print(f'\\nData Loading Completed in {total_duration}')\n",
    "\n",
    "else:\n",
    "    print(f'Set ingest_data to True to ingest data. Currently ingest_data={ingest_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420776e-14e3-4caf-bfed-36e4d2e9aa3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6.4 Query VectorSearch to Test Data Ingestion\n",
    "In the step below we query the Vector Search DB to verify data load is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac8c69-3a78-4eb0-993c-0f48ecd66a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_text = \"Sample resource type\"\n",
    "vs_response = vector_store.similarity_search_with_score(query=query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb83052-a59e-42a9-a4c1-71292d5ae7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(vs_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404cb45-8d3b-4744-bb17-080b7fcdcab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering by Semantic Search Score\n",
    "def filter_result_by_score(min_score: float, vs_respone: list) -> list:\n",
    "    filtered_results = []\n",
    "    \n",
    "    for doc, score in vs_response:\n",
    "        if score >= min_score:\n",
    "            filtered_results.append((doc, score))\n",
    "    \n",
    "    return filtered_results\n",
    "\n",
    "    \n",
    "min_score = 0.7        \n",
    "filtered_results = filter_result_by_score(min_score, vs_response)\n",
    "len(filtered_results) # We will now get results with score min_score (0.7) and above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e14c06-d711-4aaa-a18b-eb774e2d0c40",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 7. Retrieval Augnemented Generation\n",
    "\n",
    "Let us now proceed building the RAG in the next Notebook - [02_FHIR_RAG.ipynb](https://github.com/adethyaa/unlock-fhir-with-rag-on-vertexai/blob/main/02_FHIR_RAG.ipynb)\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
